{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDcxzy7UJqf88T4KZDWGe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecastelob/Projeto_AI_Alura_Google/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google"
      ],
      "metadata": {
        "id": "5PKWvJWH20Mg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2TO6GKi8wtVB"
      },
      "outputs": [],
      "source": [
        "pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexão com o Google IA"
      ],
      "metadata": {
        "id": "pjhyLGKP2yX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "#from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY='AIzaSyCQ3YvDsncOsOWlufosaBAzxkAORb_d1jA'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "JrXO1Zms3AbY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis do Google Gemini"
      ],
      "metadata": {
        "id": "_eHqOL-O3OoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "_XCe9Ptx3M3n",
        "outputId": "b541606b-1a15-45b1-b1cf-6d77a05d62ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARAMETRIZAÇÃO DO MODELO\n",
        "PARÂMETROS DO GOOGLE AI"
      ],
      "metadata": {
        "id": "c-8X6QL66f4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 0.5\n",
        "}\n"
      ],
      "metadata": {
        "id": "9N5qkzrr5SyR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings ={\n",
        "    \"HARASSMENT\" : \"BLOCK_NONE\" ,\n",
        "    \"HATE\" :  \"BLOCK_NONE\" ,\n",
        "    \"SEXUAL\" :  \"BLOCK_NONE\" ,\n",
        "    \"DANGEROUS\" :  \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "rNgrOfew57JR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INICIALIZANDO O MODELO"
      ],
      "metadata": {
        "id": "VWNYDuW965Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "3iV76ngs64TM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Escreva uma história sobre o futuro do trabalho.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "x2g2e70D8sTA",
        "outputId": "ae4bfc16-f0c5-4cf2-e632-43ae62c40c53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No ano de 2045, o cenário do trabalho havia se transformado irreconhecível. A automação e a inteligência artificial (IA) haviam revolucionado indústrias inteiras, levando a uma redefinição fundamental do que significava trabalhar.\n",
            "\n",
            "Ava, uma jovem brilhante, havia crescido em um mundo onde a tecnologia era onipresente. Ela se formou em engenharia de IA e conseguiu um emprego em uma empresa de ponta que desenvolvia soluções inovadoras para os desafios do futuro do trabalho.\n",
            "\n",
            "A empresa de Ava, chamada \"Synergy\", acreditava que o futuro do trabalho não era sobre substituir os humanos por máquinas, mas sim sobre capacitar as pessoas com ferramentas e conhecimento para prosperar em um mundo em constante evolução.\n",
            "\n",
            "Ava trabalhou em uma equipe que desenvolveu um sistema de IA chamado \"Mentor\". Mentor era um assistente virtual personalizado que fornecia orientação e suporte em tempo real para os funcionários. Ele poderia analisar dados, identificar tendências e sugerir estratégias para melhorar o desempenho.\n",
            "\n",
            "Com a ajuda do Mentor, os funcionários podiam aprender novas habilidades, otimizar seus fluxos de trabalho e tomar decisões mais informadas. Isso levou a um aumento significativo na produtividade e inovação.\n",
            "\n",
            "Além disso, a Synergy adotou um modelo de trabalho híbrido, permitindo que os funcionários trabalhassem de qualquer lugar com acesso à internet. Isso proporcionou maior flexibilidade e equilíbrio entre vida pessoal e profissional.\n",
            "\n",
            "Ava prosperou nesse ambiente dinâmico. Ela usou suas habilidades de IA para criar soluções criativas que melhoraram a eficiência e o bem-estar dos funcionários. Ela também se tornou uma mentora para outros, compartilhando seus conhecimentos e inspirando-os a abraçar o futuro do trabalho.\n",
            "\n",
            "O futuro do trabalho não era mais uma ameaça, mas uma oportunidade. Com a ajuda da tecnologia, os humanos podiam se concentrar em tarefas mais complexas e criativas, enquanto as máquinas cuidavam das tarefas repetitivas e rotineiras.\n",
            "\n",
            "Ava e seus colegas na Synergy estavam na vanguarda dessa transformação, criando um futuro de trabalho onde as pessoas e a tecnologia trabalhavam juntas para criar um mundo melhor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do Chat Bot"
      ],
      "metadata": {
        "id": "h_nXF22o636j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iniciando o chat bot\n",
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "ATFNBacg9PxO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\" :\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \",response.text,\"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "lsxoJEWI-Cwt",
        "outputId": "a647544f-1c65-474d-ab45-4791ea927c6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Qual a capital do Japão?\n",
            "Resposta:  Tóquio \n",
            "\n",
            "Esperando prompt: quantos habitantes moram lá?\n",
            "Resposta:  Cerca de 9 milhões de habitantes (2023) \n",
            "\n",
            "Esperando prompt: quantos são do sexo feminino?\n",
            "Resposta:  Cerca de 4,5 milhões (2023) \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# melhorando a visualização\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# imprimindo o histórico\n",
        "\n",
        "  for message in chat.history:\n",
        "    display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "    print(\"------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "re3h5WopCw59"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}